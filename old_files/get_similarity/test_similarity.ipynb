{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open(\"../img/img1.jpg\")\n",
    "img2 = Image.open(\"../img/img2.jpg\")\n",
    "img3 = Image.open(\"../img/img3.jpeg\")\n",
    "img4 = Image.open(\"../img/img4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "torch.Size([1, 3, 224, 339])\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "model.to(\"cuda\")\n",
    "tfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "img = tfms(Image.open('../img/img1.jpg')).unsqueeze(0)\n",
    "print(img.shape) # torch.Size([1, 3, 224, 224])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation1 = tfms(img1).unsqueeze(0)\n",
    "# (transformation1.shape)\n",
    "# features = model.extract_features(transformation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# room - 1: breakroom\n",
    "# halway - 1: small halway\n",
    "# halway - 2: big halway\n",
    "# halway - 3: big halway 2\n",
    "# out_office : \n",
    "# class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('../video/room_1.mp4')\n",
    "vidcap_1 = cv2.VideoCapture('../video/halway_1.mp4')\n",
    "vidcap_2 = cv2.VideoCapture('../video/halway_2.mp4')\n",
    "vidcap_3 = cv2.VideoCapture('../video/halway_3.mp4')\n",
    "vidcap_4 = cv2.VideoCapture('../video/halway_4.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1108331/219963423.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  im_vec = torch.tensor(model.extract_features(im).view(-1)).unsqueeze(0)\n",
      "/tmp/ipykernel_1108331/219963423.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  im1_vec = torch.tensor(model.extract_features(im1).view(-1)).unsqueeze(0)\n",
      "/tmp/ipykernel_1108331/219963423.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  im2_vec = torch.tensor(model.extract_features(im2).view(-1)).unsqueeze(0)\n",
      "/tmp/ipykernel_1108331/219963423.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  im3_vec = torch.tensor(model.extract_features(im3).view(-1)).unsqueeze(0)\n",
      "/tmp/ipykernel_1108331/219963423.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  im4_vec = torch.tensor(model.extract_features(im4).view(-1)).unsqueeze(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_1 - halway - 1: [0.46386802] \n",
      "  halway 1- halway 2: [0.5968851] \n",
      "  halway 2 - halway 3: [0.5689704] \n",
      "  halway 3 - halway 4: [0.07144782]\n",
      "room_1 - halway - 1: [0.49757802] \n",
      "  halway 1- halway 2: [0.57414734] \n",
      "  halway 2 - halway 3: [0.5027356] \n",
      "  halway 3 - halway 4: [0.06096006]\n",
      "room_1 - halway - 1: [0.6148592] \n",
      "  halway 1- halway 2: [0.604501] \n",
      "  halway 2 - halway 3: [0.5894524] \n",
      "  halway 3 - halway 4: [0.08375495]\n",
      "room_1 - halway - 1: [0.5936531] \n",
      "  halway 1- halway 2: [0.59106773] \n",
      "  halway 2 - halway 3: [0.6103294] \n",
      "  halway 3 - halway 4: [0.0976763]\n",
      "room_1 - halway - 1: [0.6410196] \n",
      "  halway 1- halway 2: [0.6200318] \n",
      "  halway 2 - halway 3: [0.6513017] \n",
      "  halway 3 - halway 4: [0.11680886]\n",
      "room_1 - halway - 1: [0.56525195] \n",
      "  halway 1- halway 2: [0.6531805] \n",
      "  halway 2 - halway 3: [0.6358902] \n",
      "  halway 3 - halway 4: [0.11377288]\n",
      "room_1 - halway - 1: [0.56624836] \n",
      "  halway 1- halway 2: [0.6591995] \n",
      "  halway 2 - halway 3: [0.5966086] \n",
      "  halway 3 - halway 4: [0.12170903]\n",
      "room_1 - halway - 1: [0.69064236] \n",
      "  halway 1- halway 2: [0.5909991] \n",
      "  halway 2 - halway 3: [0.6829907] \n",
      "  halway 3 - halway 4: [0.19244045]\n",
      "room_1 - halway - 1: [0.6364175] \n",
      "  halway 1- halway 2: [0.7003466] \n",
      "  halway 2 - halway 3: [0.69638205] \n",
      "  halway 3 - halway 4: [0.21975765]\n",
      "room_1 - halway - 1: [0.56606185] \n",
      "  halway 1- halway 2: [0.7438264] \n",
      "  halway 2 - halway 3: [0.5653799] \n",
      "  halway 3 - halway 4: [0.25742078]\n"
     ]
    }
   ],
   "source": [
    "data_b3 = []\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    success, images = vidcap_2.read()\n",
    "    success_1, images_1 = vidcap_2.read()\n",
    "    success_2, images_2 = vidcap_2.read()\n",
    "    success_3, images_3 = vidcap_2.read()\n",
    "    success_4, images_4 = vidcap_3.read()\n",
    "\n",
    "    if not (success and success_1 and success_2 and success_3 and success_4):\n",
    "        break\n",
    "\n",
    "    im = tfms(Image.fromarray(images)).unsqueeze(0).to(\"cuda\")\n",
    "    im_vec = torch.tensor(model.extract_features(im).view(-1)).unsqueeze(0)\n",
    "    im1 = tfms(Image.fromarray(images_1)).unsqueeze(0).to(\"cuda\")\n",
    "    im1_vec = torch.tensor(model.extract_features(im1).view(-1)).unsqueeze(0)\n",
    "    im2 = tfms(Image.fromarray(images_2)).unsqueeze(0).to(\"cuda\")\n",
    "    im2_vec = torch.tensor(model.extract_features(im2).view(-1)).unsqueeze(0)\n",
    "    im3 = tfms(Image.fromarray(images_3)).unsqueeze(0).to(\"cuda\")\n",
    "    im3_vec = torch.tensor(model.extract_features(im3).view(-1)).unsqueeze(0)\n",
    "    im4 = tfms(Image.fromarray(images_4)).unsqueeze(0).to(\"cuda\")\n",
    "    im4_vec = torch.tensor(model.extract_features(im4).view(-1)).unsqueeze(0)\n",
    "    im_im1 = cos(im_vec,im1_vec).cpu().numpy()\n",
    "    im1_im2 = cos(im1_vec,im2_vec).cpu().numpy()\n",
    "    im2_im3 = cos(im2_vec,im3_vec).cpu().numpy()\n",
    "    im3_im4 = cos(im3_vec,im4_vec).cpu().numpy()\n",
    "    im4_im = cos(im4_vec,im_vec).cpu().numpy()\n",
    "    print(f\"room_1 - halway - 1: {im_im1} \\n  halway 1- halway 2: {im1_im2} \\n  halway 2 - halway 3: {im2_im3} \\n  halway 3 - halway 4: {im3_im4}\")\n",
    "    data_b3.append([im_im1, im1_im2, im2_im3, im3_im4, im4_im])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.personal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d19d6e3957ea9b5395b41f04800294981ca0497c6f24b2d0808b8d9320dd80ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
